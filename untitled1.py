# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jWAVkOrjbF6dKKc_7sIDoWmv-6J4VUva
"""

!git clone https://github.com/ultralytics/yolov5

!nvidia-smi

!pip install pytorch

import torch

!python /content/drive/MyDrive/yolov5/train.py --img 640 --batch 16 --epochs 30 --data /content/drive/MyDrive/dataset/dataset.yaml --weights yolov5s.pt --cache

!python /content/drive/MyDrive/yolov5/detect.py --source /content/drive/MyDrive/detect.mp4 --weights /content/drive/MyDrive/yolov5/best.pt --conf 0.10

!python /content/drive/MyDrive/yolov5/try.py

import torch
import numpy as np
from google.colab.patches import cv2_imshow
import cv2
import time

class ObjectDetection:
    def __init__(self, weights):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights)
        self.classes = self.model.names
        self.total_count = 0  # Initialize detection count
        self.frame_count = 0  # Initialize frame count
        print("\n\nDevice Used:", self.device)

    def detect_objects(self, frame):
        results = self.score_frame(frame)
        frame_with_boxes = self.plot_boxes(results, frame.copy())

        self.frame_count += 1
        self.total_count += len(results[0])  # Count the number of detections

        detection_fps = self.frame_count / (time.time() - self.start_time)

        detection_text = f"FPS: {detection_fps:.2f}, Total Count: {self.total_count}"
        cv2.putText(frame_with_boxes, detection_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return frame_with_boxes

    def score_frame(self, frame):
        self.model.to(self.device)
        results = self.model(frame)
        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]
        return labels, cord

    def plot_boxes(self, results, frame):
        labels, cord = results
        n = len(labels)
        x_shape, y_shape = frame.shape[1], frame.shape[0]
        label_color = {
            'PERSON_TRYING': (55, 139, 7),
            'PERSON_ENTERED': (19, 243, 18),

        }

        for i in range(n):
            row = cord[i]
            if row[4] >= 0.2:
                x1, y1, x2, y2 = int(row[0] * x_shape), int(row[1] * y_shape), int(row[2] * x_shape), int(row[3] * y_shape)
                label = self.class_to_label(labels[i])
                bgr = label_color.get(label, (0, 0, 0))
                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)
                cv2.putText(frame, label, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)

        return frame

    def class_to_label(self, x):
        return self.classes[int(x)]

def main():
    detection = ObjectDetection(weights='/content/drive/MyDrive/yolov5/best.pt')
    input_video_path = '/content/drive/MyDrive/detect.mp4'
    output_video_path = '/content/drive/MyDrive/yolov5/result.avi'

    cap = cv2.VideoCapture(input_video_path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (width, height))

    detection.start_time = time.time()  # Initialize time for FPS calculation

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_with_boxes = detection.detect_objects(frame)
        out.write(frame_with_boxes)

        cv2_imshow(frame_with_boxes)  # Use cv2_imshow instead of cv2.imshow

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    out.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()

import torch
import numpy as np
from google.colab.patches import cv2_imshow
import cv2
import time

class ObjectDetection:
    def __init__(self, weights):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights)
        self.classes = self.model.names
        self.total_count = 0  # Initialize detection count
        self.frame_count = 0  # Initialize frame count
        print("\n\nDevice Used:", self.device)

    def detect_objects(self, frame):
        results = self.score_frame(frame)
        frame_with_boxes = self.plot_boxes(results, frame.copy())

        self.frame_count += 1
        self.total_count += len(results[0])  # Count the number of detections

        detection_fps = self.frame_count / (time.time() - self.start_time)

        detection_text = f"FPS: {detection_fps:.2f}, Total Count: {self.total_count}"
        cv2.putText(frame_with_boxes, detection_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return frame_with_boxes, results

    def score_frame(self, frame):
        self.model.to(self.device)
        results = self.model(frame)
        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]
        return labels, cord

    def plot_boxes(self, results, frame):
        labels, cord = results
        n = len(labels)
        x_shape, y_shape = frame.shape[1], frame.shape[0]
        label_color = {
            'PERSON_TRYING': (55, 139, 7),
            'PERSON_ENTERED': (19, 243, 18),

        }

        for i in range(n):
            row = cord[i]
            if row[4] >= 0.2:
                x1, y1, x2, y2 = int(row[0] * x_shape), int(row[1] * y_shape), int(row[2] * x_shape), int(row[3] * y_shape)
                label = self.class_to_label(labels[i])
                bgr = label_color.get(label, (0, 0, 0))
                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)
                cv2.putText(frame, label, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)

        return frame

    def class_to_label(self, x):
        return self.classes[int(x)]

def main():
    detection1 = ObjectDetection(weights='/content/drive/MyDrive/yolov5/best.pt')
    detection2 = ObjectDetection(weights='/content/drive/MyDrive/yolov5/best.pt')
    input_video_path1 = '/content/drive/MyDrive/detect.mp4'
    input_video_path2 = '/content/drive/MyDrive/yolov5/detect2.mp4'
    output_video_path = '/content/drive/MyDrive/yolov5/result.avi'
    output_frame_path = '/content/drive/MyDrive/yolov5/frames'

    cap1 = cv2.VideoCapture(input_video_path1)
    cap2 = cv2.VideoCapture(input_video_path2)

    width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))

    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (width * 2, height))

    detection1.start_time = time.time()  # Initialize time for FPS calculation
    detection2.start_time = time.time()  # Initialize time for FPS calculation

    while True:
        ret1, frame1 = cap1.read()
        ret2, frame2 = cap2.read()

        if not ret1 or not ret2:
            break

        frame_with_boxes1, results1 = detection1.detect_objects(frame1)
        frame2_resized = cv2.resize(frame2, (width, height))
        frame_with_boxes2, results2 = detection2.detect_objects(frame2_resized)

        combined_frame = np.concatenate((frame_with_boxes1, frame_with_boxes2), axis=1)
        out.write(combined_frame)

        cv2_imshow(combined_frame)

        # Saving frames
        if len(results1[0]) > 0:
            cv2.imwrite(output_frame_path + f"frame1_{detection1.frame_count}.jpg", frame1)
        if len(results2[0]) > 0:
            cv2.imwrite(output_frame_path + f"frame2_{detection2.frame_count}.jpg", frame2)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap1.release()
    cap2.release()
    out.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()

import torch
import numpy as np
from google.colab.patches import cv2_imshow
import cv2
import time

# Define the ObjectDetection class
class ObjectDetection:
    # Constructor
    def __init__(self, weights):
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=weights)
        self.classes = self.model.names
        self.total_count = 0  # Initialize detection count
        self.frame_count = 0  # Initialize frame count
        print("\n\nDevice Used:", self.device)
        self.start_time = time.time()  # Initialize start time

    # Detect objects in a frame
    def detect_objects(self, frame):
        results = self.score_frame(frame)
        frame_with_boxes = self.plot_boxes(results, frame.copy())

        self.frame_count += 1
        self.total_count += len(results[0])  # Count the number of detections

        detection_fps = self.frame_count / (time.time() - self.start_time)

        detection_text = f"FPS: {detection_fps:.2f}, Total Count: {self.total_count}"
        cv2.putText(frame_with_boxes, detection_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

        return frame_with_boxes, len(results[0]) > 0

    # Score the frame
    def score_frame(self, frame):
        self.model.to(self.device)
        results = self.model(frame)
        labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]
        return labels, cord

    # Plot bounding boxes and labels
    def plot_boxes(self, results, frame):
        labels, cord = results
        n = len(labels)
        x_shape, y_shape = frame.shape[1], frame.shape[0]
        label_color = {
            'PERSON_TRYING': (55, 139, 7),
            'PERSON_ENTERED': (19, 243, 18),
        }

        for i in range(n):
            row = cord[i]
            if row[4] >= 0.2:
                x1, y1, x2, y2 = int(row[0] * x_shape), int(row[1] * y_shape), int(row[2] * x_shape), int(row[3] * y_shape)
                label = self.class_to_label(labels[i])
                bgr = label_color.get(label, (0, 0, 0))
                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)
                cv2.putText(frame, label, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)

        return frame

    # Convert class index to label
    def class_to_label(self, x):
        return self.classes[int(x)]

# Main function
def main():
    detection1 = ObjectDetection(weights='/content/drive/MyDrive/yolov5/best.pt')
    detection2 = ObjectDetection(weights='/content/drive/MyDrive/yolov5/best.pt')
    input_video_path1 = '/content/drive/MyDrive/detect1.mp4'
    input_video_path2 = '/content/drive/MyDrive/yolov5/detect2.mp4'
    output_video_path = '/content/drive/MyDrive/yolov5/result.avi'
    frame_output_folder = '/content/drive/MyDrive/yolov5/frames/'

    cap1 = cv2.VideoCapture(input_video_path1)
    cap2 = cv2.VideoCapture(input_video_path2)

    width = int(cap1.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT))

    out = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (width * 2, height))

    detection1.start_time = time.time()  # Initialize time for FPS calculation
    detection2.start_time = time.time()  # Initialize time for FPS calculation

    anomaly_detected = False
    clip_duration = 3  # in seconds
    fourcc = cv2.VideoWriter_fourcc(*'XVID')

    while True:
        ret1, frame1 = cap1.read()
        ret2, frame2 = cap2.read()

        if not ret1 or not ret2:
            break

        frame_with_boxes1, anomaly1 = detection1.detect_objects(frame1)
        frame2_resized = cv2.resize(frame2, (width, height))
        frame_with_boxes2, anomaly2 = detection2.detect_objects(frame2_resized)

        combined_frame = np.concatenate((frame_with_boxes1, frame_with_boxes2), axis=1)
        out.write(combined_frame)

        cv2_imshow(combined_frame)

        if anomaly1 or anomaly2:
            current_time = time.time()
            clip_out1 = cv2.VideoWriter(f'{frame_output_folder}anomaly_clip_{current_time}_1.avi', fourcc, 20.0, (width, height))
            clip_out2 = cv2.VideoWriter(f'{frame_output_folder}anomaly_clip_{current_time}_2.avi', fourcc, 20.0, (width, height))

            start_time = time.time()
            while int(time.time() - start_time) < clip_duration:
                ret1, frame1 = cap1.read()
                ret2, frame2 = cap2.read()

                if not ret1 or not ret2:
                    break

                if not frame1.size == 0:
                    clip_out1.write(frame1)
                if not frame2.size == 0:
                    clip_out2.write(frame2)

            clip_out1.release()
            clip_out2.release()

        # Save frames
        if not frame1.size == 0:
            cv2.imwrite(f'{frame_output_folder}frame1_{detection1.frame_count}.jpg', frame1)
        if not frame2.size == 0:
            cv2.imwrite(f'{frame_output_folder}frame2_{detection2.frame_count}.jpg', frame2)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap1.release()
    cap2.release()
    out.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()

self.device = 'cuda' if torch.cuda.is_available() else 'cpu'

import torch
print(torch.cuda.is_available())